{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cde22a",
   "metadata": {},
   "source": [
    "# Baseline CAPTCHA Recognition Model\n",
    "\n",
    "This notebook implements a simple CNN baseline model for CAPTCHA recognition. The baseline uses a classic convolutional neural network architecture to demonstrate the baseline performance, which highlights the superiority of our custom approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872aa1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd96a9f",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "Define the character set and dataset parameters for CAPTCHA recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6b30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of character classes: 36\n",
      "Character set: 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "Maximum CAPTCHA length: 8\n"
     ]
    }
   ],
   "source": [
    "# Define character set (digits + lowercase letters)\n",
    "CHARACTERS = string.digits + string.ascii_lowercase  # '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "NUM_CLASSES = len(CHARACTERS)  # 36 classes\n",
    "MAX_LENGTH = 8  # Maximum CAPTCHA length\n",
    "\n",
    "# Create character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(CHARACTERS)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(CHARACTERS)}\n",
    "\n",
    "# Data paths\n",
    "TRAIN_DIR = 'processed/train'\n",
    "TEST_DIR = 'processed/test'\n",
    "\n",
    "print(f\"Number of character classes: {NUM_CLASSES}\")\n",
    "print(f\"Character set: {CHARACTERS}\")\n",
    "print(f\"Maximum CAPTCHA length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55eb903",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "\n",
    "Create a PyTorch Dataset for loading CAPTCHA images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "627b9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class created successfully\n"
     ]
    }
   ],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Extract label from filename (format: label-0.png)\n",
    "        label_str = img_name.split('-')[0].lower()\n",
    "        \n",
    "        # Convert label string to list of indices\n",
    "        label_indices = [char_to_idx[c] for c in label_str]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label_indices, label_str\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 200)),  # Resize to standard size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom collate function for variable length labels\n",
    "def collate_fn(batch):\n",
    "    images, labels, label_strs = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    \n",
    "    # Get label lengths\n",
    "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "    \n",
    "    # Flatten all labels into one tensor\n",
    "    labels = [item for sublist in labels for item in sublist]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return images, labels, label_lengths, label_strs\n",
    "\n",
    "print(\"Dataset class created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b4bf4",
   "metadata": {},
   "source": [
    "## Simplified Baseline CRNN Model with CTC Loss\n",
    "\n",
    "Define a simplified CRNN architecture appropriate for ~8K training samples. Uses fewer conv blocks and a single-layer LSTM to reduce model complexity and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3589281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "Total parameters: 2,153,381\n",
      "Model architecture simplified for 7836 training samples\n"
     ]
    }
   ],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_height=64, num_classes=NUM_CLASSES):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simplified CNN for feature extraction (4 blocks instead of 6)\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Conv block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 32x100\n",
    "            \n",
    "            # Conv block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 16x50\n",
    "            \n",
    "            # Conv block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 1)),  # 8x50\n",
    "            \n",
    "            # Conv block 4\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 1)),  # 4x50\n",
    "        )\n",
    "        \n",
    "        # Calculate the height after convolutions: 64 -> 32 -> 16 -> 8 -> 4 = 4\n",
    "        self.rnn_input_size = 256 * 4  # 1024\n",
    "        \n",
    "        # Single-layer Bidirectional LSTM with smaller hidden size\n",
    "        self.rnn = nn.LSTM(\n",
    "            self.rnn_input_size,\n",
    "            128,  # Reduced from 256 to 128\n",
    "            num_layers=1,  # Reduced from 2 to 1\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.0\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128 * 2, num_classes + 1)  # +1 for CTC blank\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        conv = self.cnn(x)  # [batch, 256, 4, width]\n",
    "        \n",
    "        # Reshape for RNN: [batch, width, channels*height]\n",
    "        batch, channel, height, width = conv.size()\n",
    "        conv = conv.permute(0, 3, 1, 2)  # [batch, width, channel, height]\n",
    "        conv = conv.contiguous().view(batch, width, channel * height)\n",
    "        \n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(conv)  # [batch, width, 256]\n",
    "        \n",
    "        # Fully connected\n",
    "        output = self.fc(rnn_out)  # [batch, width, num_classes+1]\n",
    "        \n",
    "        # For CTC loss: [width, batch, num_classes+1]\n",
    "        output = output.permute(1, 0, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CRNN(img_height=64, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "print(f\"Model initialized on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model architecture simplified for {len(train_dataset) if 'train_dataset' in dir() else '~8K'} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896a98c",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Initialize data loaders, loss function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908c3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 7836\n",
      "Test samples: 2000\n",
      "Batch size: 64\n",
      "Using CTC Loss with blank index: 36\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CaptchaDataset(TRAIN_DIR, transform=transform)\n",
    "test_dataset = CaptchaDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "# Create data loaders with custom collate function\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         num_workers=0, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# CTC Loss and optimizer\n",
    "criterion = nn.CTCLoss(blank=NUM_CLASSES, zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Using CTC Loss with blank index: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13fc2c",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "Define the training loop for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "285e4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for images, labels, label_lengths, _ in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)  # [T, N, C] where T=width, N=batch, C=classes\n",
    "        \n",
    "        # Calculate input lengths (all same for this model)\n",
    "        input_lengths = torch.full(size=(images.size(0),), \n",
    "                                   fill_value=outputs.size(0), \n",
    "                                   dtype=torch.long,\n",
    "                                   device=device)\n",
    "        \n",
    "        # CTC Loss\n",
    "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': total_loss / (progress_bar.n + 1)})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fc639",
   "metadata": {},
   "source": [
    "## Evaluation Function\n",
    "\n",
    "Define the evaluation function to test the model and return predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49c61cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def decode_predictions(outputs):\n",
    "    \"\"\"Decode CTC outputs to strings\"\"\"\n",
    "    # outputs: [T, N, C]\n",
    "    _, preds = outputs.max(2)  # [T, N]\n",
    "    preds = preds.transpose(1, 0).contiguous()  # [N, T]\n",
    "    \n",
    "    decoded = []\n",
    "    for i in range(preds.size(0)):\n",
    "        pred = preds[i]\n",
    "        # Remove blanks and duplicates\n",
    "        pred_text = []\n",
    "        prev_char = None\n",
    "        for char_idx in pred:\n",
    "            char_idx = char_idx.item()\n",
    "            if char_idx != NUM_CLASSES and char_idx != prev_char:  # Not blank and not duplicate\n",
    "                pred_text.append(idx_to_char[char_idx])\n",
    "            prev_char = char_idx\n",
    "        decoded.append(''.join(pred_text))\n",
    "    \n",
    "    return decoded\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Evaluating')\n",
    "        \n",
    "        for images, labels, label_lengths, label_strs in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            label_lengths = label_lengths.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate input lengths\n",
    "            input_lengths = torch.full(size=(images.size(0),), \n",
    "                                      fill_value=outputs.size(0), \n",
    "                                      dtype=torch.long,\n",
    "                                      device=device)\n",
    "            \n",
    "            # CTC Loss\n",
    "            loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Decode predictions\n",
    "            pred_strs = decode_predictions(outputs)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            for pred, true in zip(pred_strs, label_strs):\n",
    "                if pred == true:\n",
    "                    correct_sequences += 1\n",
    "                \n",
    "                # Character-level accuracy\n",
    "                min_len = min(len(pred), len(true))\n",
    "                for i in range(min_len):\n",
    "                    if pred[i] == true[i]:\n",
    "                        correct_chars += 1\n",
    "                total_chars += len(true)\n",
    "            \n",
    "            total_sequences += len(label_strs)\n",
    "            \n",
    "            seq_acc = 100 * correct_sequences / total_sequences\n",
    "            char_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': total_loss / (progress_bar.n + 1),\n",
    "                'char_acc': char_acc,\n",
    "                'seq_acc': seq_acc\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    char_accuracy = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "    seq_accuracy = 100 * correct_sequences / total_sequences\n",
    "    \n",
    "    return avg_loss, char_accuracy, seq_accuracy\n",
    "\n",
    "def predict_captcha(model, image, device):\n",
    "    \"\"\"Predict CAPTCHA text from an image and return as string\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        outputs = model(image)\n",
    "        pred_strs = decode_predictions(outputs)\n",
    "        return pred_strs[0]\n",
    "\n",
    "print(\"Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f40d01",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the baseline model for multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a53b7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.38it/s, loss=4.32]\n",
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.38it/s, loss=4.32]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.52it/s, loss=4.3, char_acc=0, seq_acc=0] \n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.52it/s, loss=4.3, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 4.3165\n",
      "Test Loss: 4.2982 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 2/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.41it/s, loss=3.88]\n",
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.41it/s, loss=3.88]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.49it/s, loss=4.49, char_acc=0.00833, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.49it/s, loss=4.49, char_acc=0.00833, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.8760\n",
      "Test Loss: 4.4926 | Test Char Acc: 0.01% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 3/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.41it/s, loss=3.37]\n",
      "Training: 100%|██████████| 123/123 [00:22<00:00,  5.41it/s, loss=3.37]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.62it/s, loss=2.53, char_acc=27.1, seq_acc=1.1] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.3743\n",
      "Test Loss: 2.5283 | Test Char Acc: 27.07% | Test Seq Acc: 1.10%\n",
      "✓ Best model saved with sequence accuracy: 1.10%\n",
      "\n",
      "Epoch 4/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:23<00:00,  5.32it/s, loss=1.84]\n",
      "Training: 100%|██████████| 123/123 [00:23<00:00,  5.32it/s, loss=1.84]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.41it/s, loss=1.86, char_acc=40.7, seq_acc=6.65]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.8411\n",
      "Test Loss: 1.8606 | Test Char Acc: 40.72% | Test Seq Acc: 6.65%\n",
      "✓ Best model saved with sequence accuracy: 6.65%\n",
      "\n",
      "Epoch 5/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:23<00:00,  5.31it/s, loss=1.2] \n",
      "Training: 100%|██████████| 123/123 [00:23<00:00,  5.31it/s, loss=1.2]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.72it/s, loss=5.07, char_acc=51.5, seq_acc=9.55]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.2003\n",
      "Test Loss: 5.0731 | Test Char Acc: 51.49% | Test Seq Acc: 9.55%\n",
      "✓ Best model saved with sequence accuracy: 9.55%\n",
      "\n",
      "Epoch 6/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.85it/s, loss=0.93] \n",
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.85it/s, loss=0.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.49it/s, loss=1.68, char_acc=52.1, seq_acc=12.1]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.49it/s, loss=1.68, char_acc=52.1, seq_acc=12.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.9298\n",
      "Test Loss: 1.6800 | Test Char Acc: 52.14% | Test Seq Acc: 12.10%\n",
      "✓ Best model saved with sequence accuracy: 12.10%\n",
      "\n",
      "Epoch 7/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.99it/s, loss=0.757]\n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.99it/s, loss=0.757]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.61it/s, loss=1.22, char_acc=61.6, seq_acc=21.1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.7566\n",
      "Test Loss: 1.2202 | Test Char Acc: 61.61% | Test Seq Acc: 21.10%\n",
      "✓ Best model saved with sequence accuracy: 21.10%\n",
      "\n",
      "Epoch 8/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.99it/s, loss=0.63] \n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.99it/s, loss=0.63]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.41it/s, loss=1.39, char_acc=58.7, seq_acc=18.9]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.41it/s, loss=1.39, char_acc=58.7, seq_acc=18.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.6296\n",
      "Test Loss: 1.3863 | Test Char Acc: 58.70% | Test Seq Acc: 18.90%\n",
      "\n",
      "Epoch 9/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.92it/s, loss=0.531]\n",
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.92it/s, loss=0.531]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.63it/s, loss=1.14, char_acc=62.7, seq_acc=23.1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.5306\n",
      "Test Loss: 1.1369 | Test Char Acc: 62.66% | Test Seq Acc: 23.05%\n",
      "✓ Best model saved with sequence accuracy: 23.05%\n",
      "\n",
      "Epoch 10/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.94it/s, loss=0.441]\n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.94it/s, loss=0.441]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.47it/s, loss=1.27, char_acc=66.2, seq_acc=23.1]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.47it/s, loss=1.27, char_acc=66.2, seq_acc=23.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.4406\n",
      "Test Loss: 1.2676 | Test Char Acc: 66.24% | Test Seq Acc: 23.15%\n",
      "✓ Best model saved with sequence accuracy: 23.15%\n",
      "\n",
      "Epoch 11/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.89it/s, loss=0.359]\n",
      "Training: 100%|██████████| 123/123 [00:25<00:00,  4.89it/s, loss=0.359]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.44it/s, loss=4.26, char_acc=28, seq_acc=0.6]    \n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.44it/s, loss=4.26, char_acc=28, seq_acc=0.6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.3595\n",
      "Test Loss: 4.2626 | Test Char Acc: 27.99% | Test Seq Acc: 0.60%\n",
      "\n",
      "Epoch 12/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.96it/s, loss=0.288]\n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.96it/s, loss=0.288]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.68it/s, loss=1.38, char_acc=63.1, seq_acc=18.8]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.68it/s, loss=1.38, char_acc=63.1, seq_acc=18.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2876\n",
      "Test Loss: 1.3849 | Test Char Acc: 63.06% | Test Seq Acc: 18.75%\n",
      "\n",
      "Epoch 13/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.98it/s, loss=0.23] \n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.98it/s, loss=0.23]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.55it/s, loss=0.831, char_acc=73.5, seq_acc=36.2]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.55it/s, loss=0.831, char_acc=73.5, seq_acc=36.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2295\n",
      "Test Loss: 0.8312 | Test Char Acc: 73.52% | Test Seq Acc: 36.20%\n",
      "✓ Best model saved with sequence accuracy: 36.20%\n",
      "\n",
      "Epoch 14/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.96it/s, loss=0.18] \n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  4.96it/s, loss=0.18] \n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.59it/s, loss=1.21, char_acc=60.4, seq_acc=25.2]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.59it/s, loss=1.21, char_acc=60.4, seq_acc=25.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1801\n",
      "Test Loss: 1.2058 | Test Char Acc: 60.44% | Test Seq Acc: 25.20%\n",
      "\n",
      "Epoch 15/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:24<00:00,  5.00it/s, loss=0.141]\n",
      "Training: 100%|██████████| 123/123 [00:24<00:00,  5.00it/s, loss=0.141]\n",
      "Evaluating: 100%|██████████| 32/32 [00:05<00:00,  5.64it/s, loss=2.19, char_acc=62.6, seq_acc=19.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1414\n",
      "Test Loss: 2.1883 | Test Char Acc: 62.64% | Test Seq Acc: 19.45%\n",
      "\n",
      "==================================================\n",
      "Training completed!\n",
      "Best Test Sequence Accuracy: 36.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 15  # Reduced from 20 to prevent overfitting on smaller dataset\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'test_char_acc': [],\n",
    "    'test_seq_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "best_seq_acc = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_char_acc, test_seq_acc = evaluate(model, test_loader, criterion, device)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_char_acc'].append(test_char_acc)\n",
    "    history['test_seq_acc'].append(test_seq_acc)\n",
    "    \n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Char Acc: {test_char_acc:.2f}% | Test Seq Acc: {test_seq_acc:.2f}%\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_seq_acc > best_seq_acc:\n",
    "        best_seq_acc = test_seq_acc\n",
    "        torch.save(model.state_dict(), 'baseline_best_model.pth')\n",
    "        print(f\"✓ Best model saved with sequence accuracy: {best_seq_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best Test Sequence Accuracy: {best_seq_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7bd84",
   "metadata": {},
   "source": [
    "## Test Predictions\n",
    "\n",
    "Test the model on sample images and display predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry Jian\\AppData\\Local\\Temp\\ipykernel_18500\\747743999.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('baseline_best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n",
      "============================================================\n",
      "✗ Sample 1: True: '002e23' | Predicted: '0o2e23'\n",
      "✗ Sample 2: True: '03yl9s' | Predicted: 'o3yl9s'\n",
      "✗ Sample 3: True: '03yuav5' | Predicted: 'd3yvov5'\n",
      "✗ Sample 4: True: '03zl9o' | Predicted: '03zl90'\n",
      "✗ Sample 5: True: '04zqohgi' | Predicted: '0yzh9'\n",
      "✓ Sample 6: True: '05htm' | Predicted: '05htm'\n",
      "✗ Sample 7: True: '05pb' | Predicted: 'd5rb'\n",
      "✗ Sample 8: True: '07oj' | Predicted: '00u'\n",
      "✓ Sample 9: True: '07z0' | Predicted: '07z0'\n",
      "✗ Sample 10: True: '08ft2e2z' | Predicted: 'o0ft2e2z'\n",
      "\n",
      "============================================================\n",
      "Accuracy on samples: 20.0%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('baseline_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test on a few samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get some test samples\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i in range(10):\n",
    "    img, _, label_str = test_dataset[i]\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label_str)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\" * 60)\n",
    "correct_count = 0\n",
    "for i, (img, true_label) in enumerate(zip(test_images, test_labels)):\n",
    "    predicted_text = predict_captcha(model, img, device)\n",
    "    match = \"✓\" if predicted_text == true_label else \"✗\"\n",
    "    if predicted_text == true_label:\n",
    "        correct_count += 1\n",
    "    print(f\"{match} Sample {i+1}: True: '{true_label}' | Predicted: '{predicted_text}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Accuracy on samples: {100 * correct_count / len(test_images):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7497b",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display the training history and final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Character Accuracy\n",
    "axes[1].plot(history['test_char_acc'], label='Test Char Acc', marker='s', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Character-Level Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Sequence Accuracy\n",
    "axes[2].plot(history['test_seq_acc'], label='Test Seq Acc', marker='s', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_title('Sequence-Level Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SIMPLIFIED BASELINE CRNN MODEL FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Test Character Accuracy: {max(history['test_char_acc']):.2f}%\")\n",
    "print(f\"Best Test Sequence Accuracy: {max(history['test_seq_acc']):.2f}%\")\n",
    "print(f\"Final Test Character Accuracy: {history['test_char_acc'][-1]:.2f}%\")\n",
    "print(f\"Final Test Sequence Accuracy: {history['test_seq_acc'][-1]:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis simplified baseline (~2-3M params) is appropriate for ~8K training samples\")\n",
    "print(\"and serves as a reasonable comparison point for your custom approach.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4243_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
