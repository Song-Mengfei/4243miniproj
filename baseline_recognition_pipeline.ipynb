{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cde22a",
   "metadata": {},
   "source": [
    "# Baseline CAPTCHA Recognition Model\n",
    "\n",
    "This notebook implements a simple CNN baseline model for CAPTCHA recognition. The baseline uses a classic convolutional neural network architecture to demonstrate the baseline performance, which highlights the superiority of our custom approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872aa1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd96a9f",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "Define the character set and dataset parameters for CAPTCHA recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6b30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of character classes: 36\n",
      "Character set: 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "Maximum CAPTCHA length: 8\n"
     ]
    }
   ],
   "source": [
    "# Define character set (digits + lowercase letters)\n",
    "CHARACTERS = string.digits + string.ascii_lowercase  # '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "NUM_CLASSES = len(CHARACTERS)  # 36 classes\n",
    "MAX_LENGTH = 8  # Maximum CAPTCHA length\n",
    "\n",
    "# Create character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(CHARACTERS)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(CHARACTERS)}\n",
    "\n",
    "# Data paths\n",
    "TRAIN_DIR = 'processed/train'\n",
    "TEST_DIR = 'processed/test'\n",
    "\n",
    "print(f\"Number of character classes: {NUM_CLASSES}\")\n",
    "print(f\"Character set: {CHARACTERS}\")\n",
    "print(f\"Maximum CAPTCHA length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55eb903",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "\n",
    "Create a PyTorch Dataset for loading CAPTCHA images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627b9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class created successfully\n"
     ]
    }
   ],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Extract label from filename (format: label-0.png)\n",
    "        label_str = img_name.split('-')[0].lower()\n",
    "        \n",
    "        # Convert label string to list of indices\n",
    "        label_indices = [char_to_idx[c] for c in label_str]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label_indices, label_str\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 200)),  # Resize to standard size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom collate function for variable length labels\n",
    "def collate_fn(batch):\n",
    "    images, labels, label_strs = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    \n",
    "    # Get label lengths\n",
    "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "    \n",
    "    # Flatten all labels into one tensor\n",
    "    labels = [item for sublist in labels for item in sublist]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return images, labels, label_lengths, label_strs\n",
    "\n",
    "print(\"Dataset class created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b4bf4",
   "metadata": {},
   "source": [
    "## Simplified Baseline CRNN Model with CTC Loss\n",
    "\n",
    "Define a simplified CRNN architecture appropriate for ~8K training samples. Uses fewer conv blocks and a single-layer LSTM to reduce model complexity and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3589281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "Total parameters: 10,821,285\n"
     ]
    }
   ],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_height=64, num_classes=NUM_CLASSES):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simplified CNN for feature extraction (4 blocks instead of 6)\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Conv block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 32x100\n",
    "            \n",
    "            # Conv block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 16x50\n",
    "            \n",
    "            # Conv block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 1)),  # 8x50\n",
    "            \n",
    "            # Conv block 4\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 1)),  # 4x50\n",
    "        )\n",
    "        \n",
    "        # Calculate the height after convolutions: 64 -> 32 -> 16 -> 8 -> 4 = 4\n",
    "        self.rnn_input_size = 256 * 4  # 1024\n",
    "        \n",
    "        # Single-layer Bidirectional LSTM with smaller hidden size\n",
    "        self.rnn = nn.LSTM(\n",
    "            self.rnn_input_size,\n",
    "            128,  # Reduced from 256 to 128\n",
    "            num_layers=1,  # Reduced from 2 to 1\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.0\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128 * 2, num_classes + 1)  # +1 for CTC blank\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        conv = self.cnn(x)  # [batch, 256, 4, width]\n",
    "        \n",
    "        # Reshape for RNN: [batch, width, channels*height]\n",
    "        batch, channel, height, width = conv.size()\n",
    "        conv = conv.permute(0, 3, 1, 2)  # [batch, width, channel, height]\n",
    "        conv = conv.contiguous().view(batch, width, channel * height)\n",
    "        \n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(conv)  # [batch, width, 256]\n",
    "        \n",
    "        # Fully connected\n",
    "        output = self.fc(rnn_out)  # [batch, width, num_classes+1]\n",
    "        \n",
    "        # For CTC loss: [width, batch, num_classes+1]\n",
    "        output = output.permute(1, 0, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CRNN(img_height=64, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "print(f\"Model initialized on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model architecture simplified for {len(train_dataset) if 'train_dataset' in dir() else '~8K'} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896a98c",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Initialize data loaders, loss function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908c3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 7836\n",
      "Test samples: 2000\n",
      "Batch size: 64\n",
      "Using CTC Loss with blank index: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CaptchaDataset(TRAIN_DIR, transform=transform)\n",
    "test_dataset = CaptchaDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "# Create data loaders with custom collate function\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         num_workers=0, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# CTC Loss and optimizer\n",
    "criterion = nn.CTCLoss(blank=NUM_CLASSES, zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Using CTC Loss with blank index: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13fc2c",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "Define the training loop for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "285e4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for images, labels, label_lengths, _ in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)  # [T, N, C] where T=width, N=batch, C=classes\n",
    "        \n",
    "        # Calculate input lengths (all same for this model)\n",
    "        input_lengths = torch.full(size=(images.size(0),), \n",
    "                                   fill_value=outputs.size(0), \n",
    "                                   dtype=torch.long,\n",
    "                                   device=device)\n",
    "        \n",
    "        # CTC Loss\n",
    "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': total_loss / (progress_bar.n + 1)})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fc639",
   "metadata": {},
   "source": [
    "## Evaluation Function\n",
    "\n",
    "Define the evaluation function to test the model and return predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c61cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def decode_predictions(outputs):\n",
    "    \"\"\"Decode CTC outputs to strings\"\"\"\n",
    "    # outputs: [T, N, C]\n",
    "    _, preds = outputs.max(2)  # [T, N]\n",
    "    preds = preds.transpose(1, 0).contiguous()  # [N, T]\n",
    "    \n",
    "    decoded = []\n",
    "    for i in range(preds.size(0)):\n",
    "        pred = preds[i]\n",
    "        # Remove blanks and duplicates\n",
    "        pred_text = []\n",
    "        prev_char = None\n",
    "        for char_idx in pred:\n",
    "            char_idx = char_idx.item()\n",
    "            if char_idx != NUM_CLASSES and char_idx != prev_char:  # Not blank and not duplicate\n",
    "                pred_text.append(idx_to_char[char_idx])\n",
    "            prev_char = char_idx\n",
    "        decoded.append(''.join(pred_text))\n",
    "    \n",
    "    return decoded\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Evaluating')\n",
    "        \n",
    "        for images, labels, label_lengths, label_strs in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            label_lengths = label_lengths.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate input lengths\n",
    "            input_lengths = torch.full(size=(images.size(0),), \n",
    "                                      fill_value=outputs.size(0), \n",
    "                                      dtype=torch.long,\n",
    "                                      device=device)\n",
    "            \n",
    "            # CTC Loss\n",
    "            loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Decode predictions\n",
    "            pred_strs = decode_predictions(outputs)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            for pred, true in zip(pred_strs, label_strs):\n",
    "                if pred == true:\n",
    "                    correct_sequences += 1\n",
    "                \n",
    "                # Character-level accuracy\n",
    "                min_len = min(len(pred), len(true))\n",
    "                for i in range(min_len):\n",
    "                    if pred[i] == true[i]:\n",
    "                        correct_chars += 1\n",
    "                total_chars += len(true)\n",
    "            \n",
    "            total_sequences += len(label_strs)\n",
    "            \n",
    "            seq_acc = 100 * correct_sequences / total_sequences\n",
    "            char_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': total_loss / (progress_bar.n + 1),\n",
    "                'char_acc': char_acc,\n",
    "                'seq_acc': seq_acc\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    char_accuracy = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "    seq_accuracy = 100 * correct_sequences / total_sequences\n",
    "    \n",
    "    return avg_loss, char_accuracy, seq_accuracy\n",
    "\n",
    "def predict_captcha(model, image, device):\n",
    "    \"\"\"Predict CAPTCHA text from an image and return as string\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        outputs = model(image)\n",
    "        pred_strs = decode_predictions(outputs)\n",
    "        return pred_strs[0]\n",
    "\n",
    "print(\"Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f40d01",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the baseline model for multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:43<00:00,  2.84it/s, loss=4.32]\n",
      "Evaluating: 100%|██████████| 32/32 [00:08<00:00,  4.00it/s, loss=3.93, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 4.3167\n",
      "Test Loss: 3.9270 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 2/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.14it/s, loss=3.93]\n",
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.14it/s, loss=3.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.57it/s, loss=3.93, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.57it/s, loss=3.93, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9312\n",
      "Test Loss: 3.9291 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 3/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.93]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.59it/s, loss=3.93, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.59it/s, loss=3.93, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9315\n",
      "Test Loss: 3.9289 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 4/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.20it/s, loss=3.93]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.20it/s, loss=3.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.69it/s, loss=3.93, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.69it/s, loss=3.93, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9302\n",
      "Test Loss: 3.9260 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 5/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.20it/s, loss=3.93]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.20it/s, loss=3.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.58it/s, loss=3.93, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.58it/s, loss=3.93, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9294\n",
      "Test Loss: 3.9259 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 6/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.93]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.93]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.56it/s, loss=3.92, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.56it/s, loss=3.92, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9263\n",
      "Test Loss: 3.9213 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 7/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.15it/s, loss=3.92]\n",
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.15it/s, loss=3.92]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.45it/s, loss=3.92, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.45it/s, loss=3.92, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9203\n",
      "Test Loss: 3.9183 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 8/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.92]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.92]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.45it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.45it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9192\n",
      "Test Loss: 3.9103 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 9/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.92]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.92]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.43it/s, loss=3.92, char_acc=0, seq_acc=0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9200\n",
      "Test Loss: 3.9164 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 10/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.92]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.92]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.63it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.63it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9156\n",
      "Test Loss: 3.9099 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 11/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.15it/s, loss=3.92]\n",
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.15it/s, loss=3.92]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.42it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.42it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9156\n",
      "Test Loss: 3.9083 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 12/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.91]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.17it/s, loss=3.91]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.54it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.54it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9136\n",
      "Test Loss: 3.9101 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 13/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.08it/s, loss=3.91]\n",
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.08it/s, loss=3.91]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.43it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.43it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9136\n",
      "Test Loss: 3.9096 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 14/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.91]\n",
      "Training: 100%|██████████| 123/123 [00:38<00:00,  3.18it/s, loss=3.91]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.59it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:06<00:00,  4.59it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9149\n",
      "Test Loss: 3.9102 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 15/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.12it/s, loss=3.91]\n",
      "Training: 100%|██████████| 123/123 [00:39<00:00,  3.12it/s, loss=3.91]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.05it/s, loss=3.91, char_acc=0, seq_acc=0]\n",
      "Evaluating: 100%|██████████| 32/32 [00:07<00:00,  4.05it/s, loss=3.91, char_acc=0, seq_acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.9139\n",
      "Test Loss: 3.9097 | Test Char Acc: 0.00% | Test Seq Acc: 0.00%\n",
      "\n",
      "Epoch 16/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 70/123 [00:22<00:17,  3.09it/s, loss=3.91]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     18\u001b[39m input_lengths = torch.full(size=(images.size(\u001b[32m0\u001b[39m),), \n\u001b[32m     19\u001b[39m                            fill_value=outputs.size(\u001b[32m0\u001b[39m), \n\u001b[32m     20\u001b[39m                            dtype=torch.long,\n\u001b[32m     21\u001b[39m                            device=device)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# CTC Loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     27\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1980\u001b[39m, in \u001b[36mCTCLoss.forward\u001b[39m\u001b[34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[39m\n\u001b[32m   1973\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   1974\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1975\u001b[39m     log_probs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1978\u001b[39m     target_lengths: Tensor,\n\u001b[32m   1979\u001b[39m ) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_infinity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\nn\\functional.py:3069\u001b[39m, in \u001b[36mctc_loss\u001b[39m\u001b[34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[39m\n\u001b[32m   3057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n\u001b[32m   3058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   3059\u001b[39m         ctc_loss,\n\u001b[32m   3060\u001b[39m         (log_probs, targets, input_lengths, target_lengths),\n\u001b[32m   (...)\u001b[39m\u001b[32m   3067\u001b[39m         zero_infinity=zero_infinity,\n\u001b[32m   3068\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3069\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzero_infinity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 15  # Reduced from 20 to prevent overfitting on smaller dataset\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'test_char_acc': [],\n",
    "    'test_seq_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "best_seq_acc = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_char_acc, test_seq_acc = evaluate(model, test_loader, criterion, device)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_char_acc'].append(test_char_acc)\n",
    "    history['test_seq_acc'].append(test_seq_acc)\n",
    "    \n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Char Acc: {test_char_acc:.2f}% | Test Seq Acc: {test_seq_acc:.2f}%\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_seq_acc > best_seq_acc:\n",
    "        best_seq_acc = test_seq_acc\n",
    "        torch.save(model.state_dict(), 'baseline_best_model.pth')\n",
    "        print(f\"✓ Best model saved with sequence accuracy: {best_seq_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best Test Sequence Accuracy: {best_seq_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7bd84",
   "metadata": {},
   "source": [
    "## Test Predictions\n",
    "\n",
    "Test the model on sample images and display predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('baseline_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test on a few samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get some test samples\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i in range(10):\n",
    "    img, _, label_str = test_dataset[i]\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label_str)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\" * 60)\n",
    "correct_count = 0\n",
    "for i, (img, true_label) in enumerate(zip(test_images, test_labels)):\n",
    "    predicted_text = predict_captcha(model, img, device)\n",
    "    match = \"✓\" if predicted_text == true_label else \"✗\"\n",
    "    if predicted_text == true_label:\n",
    "        correct_count += 1\n",
    "    print(f\"{match} Sample {i+1}: True: '{true_label}' | Predicted: '{predicted_text}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Accuracy on samples: {100 * correct_count / len(test_images):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7497b",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display the training history and final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Character Accuracy\n",
    "axes[1].plot(history['test_char_acc'], label='Test Char Acc', marker='s', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Character-Level Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Sequence Accuracy\n",
    "axes[2].plot(history['test_seq_acc'], label='Test Seq Acc', marker='s', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_title('Sequence-Level Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SIMPLIFIED BASELINE CRNN MODEL FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Test Character Accuracy: {max(history['test_char_acc']):.2f}%\")\n",
    "print(f\"Best Test Sequence Accuracy: {max(history['test_seq_acc']):.2f}%\")\n",
    "print(f\"Final Test Character Accuracy: {history['test_char_acc'][-1]:.2f}%\")\n",
    "print(f\"Final Test Sequence Accuracy: {history['test_seq_acc'][-1]:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis simplified baseline (~2-3M params) is appropriate for ~8K training samples\")\n",
    "print(\"and serves as a reasonable comparison point for your custom approach.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4243_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
