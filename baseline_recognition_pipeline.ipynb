{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cde22a",
   "metadata": {},
   "source": [
    "# Baseline CAPTCHA Recognition Model\n",
    "\n",
    "This notebook implements a simple CNN baseline model for CAPTCHA recognition. The baseline uses a classic convolutional neural network architecture to demonstrate the baseline performance, which highlights the superiority of our custom approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872aa1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd96a9f",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "Define the character set and dataset parameters for CAPTCHA recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6b30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of character classes: 36\n",
      "Character set: 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "Maximum CAPTCHA length: 8\n"
     ]
    }
   ],
   "source": [
    "# Define character set (digits + lowercase letters)\n",
    "CHARACTERS = string.digits + string.ascii_lowercase  # '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "NUM_CLASSES = len(CHARACTERS)  # 36 classes\n",
    "MAX_LENGTH = 8  # Maximum CAPTCHA length\n",
    "\n",
    "# Create character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(CHARACTERS)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(CHARACTERS)}\n",
    "\n",
    "# Data paths\n",
    "TRAIN_DIR = 'processed/train'\n",
    "TEST_DIR = 'processed/test'\n",
    "\n",
    "print(f\"Number of character classes: {NUM_CLASSES}\")\n",
    "print(f\"Character set: {CHARACTERS}\")\n",
    "print(f\"Maximum CAPTCHA length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55eb903",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "\n",
    "Create a PyTorch Dataset for loading CAPTCHA images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627b9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class created successfully\n"
     ]
    }
   ],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, max_length=MAX_LENGTH):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Extract label from filename (format: label-0.png)\n",
    "        label_str = img_name.split('-')[0].lower()\n",
    "        \n",
    "        # Convert to fixed-length label (pad with -1 for unused positions)\n",
    "        label = [-1] * self.max_length\n",
    "        for i, char in enumerate(label_str[:self.max_length]):\n",
    "            label[i] = char_to_idx[char]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long), label_str\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 200)),  # Resize to standard size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Dataset class created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b4bf4",
   "metadata": {},
   "source": [
    "## Simplified Baseline CNN Model\n",
    "\n",
    "Define a simplified CNN baseline using basic convolutional blocks. This baseline uses standard convolutions without advanced techniques like depthwise separable convolutions or CTC loss, making it a reasonable comparison point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3589281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "Total parameters: 1,281,856\n",
      "Trainable parameters: 1,281,856\n",
      "Architecture: Simple CNN with per-position classification\n"
     ]
    }
   ],
   "source": [
    "class SimpleResidualBlock(nn.Module):\n",
    "    \"\"\"Simplified residual block without depthwise separable convolutions\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.use_residual = (stride == 1 and in_ch == out_ch)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "        \n",
    "        # Shortcut for dimension matching\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.use_residual:\n",
    "            out = out + self.shortcut(x)\n",
    "        return nn.functional.relu(out)\n",
    "\n",
    "\n",
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"Simplified baseline CNN for single character recognition\"\"\"\n",
    "    def __init__(self, num_classes=NUM_CLASSES, max_length=MAX_LENGTH, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simple CNN backbone\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            SimpleResidualBlock(32, 64, stride=2),   # 32x100\n",
    "            SimpleResidualBlock(64, 128, stride=2),  # 16x50\n",
    "            SimpleResidualBlock(128, 256, stride=2), # 8x25\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Separate classifier head for each character position\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, num_classes)\n",
    "            ) for _ in range(max_length)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Predict each character position independently\n",
    "        outputs = [classifier(x) for classifier in self.classifiers]\n",
    "        return outputs\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BaselineCNN(num_classes=NUM_CLASSES, max_length=MAX_LENGTH).to(device)\n",
    "\n",
    "print(f\"Model initialized on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"Architecture: Simple CNN with per-position classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896a98c",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Initialize data loaders, loss function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908c3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 7836\n",
      "Test samples: 2000\n",
      "Batch size: 64\n",
      "Loss function: CrossEntropyLoss (per-position)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D\\Miniconda3\\envs\\cs4243_env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CaptchaDataset(TRAIN_DIR, transform=transform)\n",
    "test_dataset = CaptchaDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore padded positions\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Loss function: CrossEntropyLoss (per-position)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13fc2c",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "Define the training loop for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for images, labels, _ in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)  # [batch, max_length]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)  # List of [batch, num_classes] for each position\n",
    "        \n",
    "        # Calculate loss for each position\n",
    "        loss = 0\n",
    "        for pos in range(len(outputs)):\n",
    "            loss += criterion(outputs[pos], labels[:, pos])\n",
    "        loss /= len(outputs)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate character-level accuracy\n",
    "        for pos in range(len(outputs)):\n",
    "            preds = outputs[pos].argmax(dim=1)\n",
    "            mask = labels[:, pos] != -1  # Only count valid positions\n",
    "            correct_chars += (preds[mask] == labels[:, pos][mask]).sum().item()\n",
    "            total_chars += mask.sum().item()\n",
    "        \n",
    "        char_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': total_loss / (progress_bar.n + 1),\n",
    "            'char_acc': f'{char_acc:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "    \n",
    "    return avg_loss, train_acc\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fc639",
   "metadata": {},
   "source": [
    "## Evaluation Function\n",
    "\n",
    "Define the evaluation function to test the model and return predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c61cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Evaluating')\n",
    "        \n",
    "        for images, labels, label_strs in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = 0\n",
    "            for pos in range(len(outputs)):\n",
    "                loss += criterion(outputs[pos], labels[:, pos])\n",
    "            loss /= len(outputs)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions for each position\n",
    "            preds = torch.stack([out.argmax(dim=1) for out in outputs], dim=1)  # [batch, max_length]\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            for i, true_str in enumerate(label_strs):\n",
    "                pred_chars = []\n",
    "                for pos in range(len(true_str)):\n",
    "                    pred_chars.append(idx_to_char[preds[i, pos].item()])\n",
    "                pred_str = ''.join(pred_chars)\n",
    "                \n",
    "                # Sequence accuracy\n",
    "                if pred_str == true_str:\n",
    "                    correct_sequences += 1\n",
    "                \n",
    "                # Character-level accuracy\n",
    "                for j in range(len(true_str)):\n",
    "                    if pred_str[j] == true_str[j]:\n",
    "                        correct_chars += 1\n",
    "                total_chars += len(true_str)\n",
    "            \n",
    "            total_sequences += len(label_strs)\n",
    "            \n",
    "            seq_acc = 100 * correct_sequences / total_sequences\n",
    "            char_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': total_loss / (progress_bar.n + 1),\n",
    "                'char_acc': f'{char_acc:.2f}%',\n",
    "                'seq_acc': f'{seq_acc:.2f}%'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    char_accuracy = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "    seq_accuracy = 100 * correct_sequences / total_sequences\n",
    "    \n",
    "    return avg_loss, char_accuracy, seq_accuracy\n",
    "\n",
    "def predict_captcha(model, image, device):\n",
    "    \"\"\"Predict CAPTCHA text from an image and return as string\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        outputs = model(image)\n",
    "        \n",
    "        pred_chars = []\n",
    "        for out in outputs:\n",
    "            pred_idx = out.argmax(dim=1).item()\n",
    "            pred_chars.append(idx_to_char[pred_idx])\n",
    "        \n",
    "        return ''.join(pred_chars)\n",
    "\n",
    "print(\"Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f40d01",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the baseline model for multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/123 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      3\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m progress_bar = tqdm(train_loader, desc=\u001b[33m'\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, labels, label_lengths, _ \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[32m      8\u001b[39m     images = images.to(device)\n\u001b[32m      9\u001b[39m     labels = labels.to(device)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_char_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_char_acc': [],\n",
    "    'test_seq_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "best_seq_acc = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_char_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_char_acc'].append(train_char_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_char_acc, test_seq_acc = evaluate(model, test_loader, criterion, device)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_char_acc'].append(test_char_acc)\n",
    "    history['test_seq_acc'].append(test_seq_acc)\n",
    "    \n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Char Acc: {train_char_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Char Acc: {test_char_acc:.2f}% | Test Seq Acc: {test_seq_acc:.2f}%\")\n",
    "    \n",
    "    # Learning rate scheduling based on sequence accuracy\n",
    "    scheduler.step(test_seq_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_seq_acc > best_seq_acc:\n",
    "        best_seq_acc = test_seq_acc\n",
    "        torch.save(model.state_dict(), 'baseline_best_model.pth')\n",
    "        print(f\"✓ Best model saved with sequence accuracy: {best_seq_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best Test Sequence Accuracy: {best_seq_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7bd84",
   "metadata": {},
   "source": [
    "## Test Predictions\n",
    "\n",
    "Test the model on sample images and display predictions as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('baseline_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test on a few samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get some test samples\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i in range(10):\n",
    "    img, _, label_str = test_dataset[i]\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label_str)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\" * 60)\n",
    "correct_count = 0\n",
    "for i, (img, true_label) in enumerate(zip(test_images, test_labels)):\n",
    "    predicted_text = predict_captcha(model, img, device)\n",
    "    match = \"✓\" if predicted_text == true_label else \"✗\"\n",
    "    if predicted_text == true_label:\n",
    "        correct_count += 1\n",
    "    print(f\"{match} Sample {i+1}: True: '{true_label}' | Predicted: '{predicted_text}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Accuracy on samples: {100 * correct_count / len(test_images):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7497b",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display the training history and final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0, 0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Test Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Character Accuracy\n",
    "axes[0, 1].plot(history['train_char_acc'], label='Train Char Acc', marker='o', color='blue')\n",
    "axes[0, 1].plot(history['test_char_acc'], label='Test Char Acc', marker='s', color='orange')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Character-Level Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Sequence Accuracy\n",
    "axes[1, 0].plot(history['test_seq_acc'], label='Test Seq Acc', marker='s', color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].set_title('Sequence-Level Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Hide empty subplot\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SIMPLIFIED BASELINE CNN MODEL FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Test Character Accuracy: {max(history['test_char_acc']):.2f}%\")\n",
    "print(f\"Best Test Sequence Accuracy: {max(history['test_seq_acc']):.2f}%\")\n",
    "print(f\"Final Test Character Accuracy: {history['test_char_acc'][-1]:.2f}%\")\n",
    "print(f\"Final Test Sequence Accuracy: {history['test_seq_acc'][-1]:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"This simplified baseline uses standard convolutions with per-position\")\n",
    "print(\"classification, serving as a reasonable comparison point.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4243_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
